---
title: "Final Data Modeling"
author: "Aru Gupta"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r include=FALSE}
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
library(ezids)
 
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r}

# Installing Packages
install.packages("e1071")
install.packages("caTools")
install.packages("class")
  
# Loading package
library(e1071)
library(caTools)
library(class)
loadPkg("ggplot2")
```


# Loading Data sets 
```{r }
WildfireData <- read.csv('final_wildfire.csv')
summary_nature=read.csv('summary_nature.csv')
summary_peoplecaused=read.csv('summary_peoplecaused.csv')
fire_budget  <- read.csv("fire_suppression.csv")


colnames(summary_nature)[7]='nature_fire'
summary_nature$people_caused_fires=summary_peoplecaused$n
summary_nature$total=summary_nature$nature_fire+summary_peoplecaused$n
```


```{r}

Avg_Temp <- summary_nature$tair_day_livneh_vic
Avg_SoilMoisture <- summary_nature$soilmoist1_day_livneh_vic
Avg_Rainfall <- summary_nature$rainfall_day_livneh_vic

```


# Contigency Tables 

```{r crosstable}
totalFiretable = xtabs(total ~ Avg_Temp + Avg_SoilMoisture + Avg_Rainfall, data = summary_nature)

totalFiretable
```


# Logistic Regression

```{r logitmodel}
logitTotal <- glm(log(total)~Avg_Temp + Avg_SoilMoisture + Avg_Rainfall, data = summary_nature)
#summary(logitTotal)
```
```{r results='markup'}
xkabledply(logitTotal, title = paste("Logistic Regression :", format(formula(logitTotal)) ))
#predict(logitTotal)
```


```{r logitmodel}
logitFireSize <- glm(FIRE_SIZE ~ Avg_Temp + Avg_SoilMoisture + Avg_Rainfall, data = summary_nature)
#summary(logitFireSize)
```
```{r results='markup'}
xkabledply(logitFireSize, title = paste("Logistic Regression :", format(formula(logitFireSize)) ))
```


```{r logitmodel}
logitMonth <- glm(month ~ FIRE_SIZE + Avg_Temp + Avg_SoilMoisture + Avg_Rainfall, data = summary_nature)
#summary(logitMonth)
```
```{r results='markup'}
xkabledply(logitMonth, title = paste("Logistic Regression :", format(formula(logitMonth)) ))
```

#Basic Visualization 

```{r}
loadPkg("FNN")
#For this example we are going to use the IRIS dataset in R
str(summary_nature)
loadPkg('ggplot2')
```

```{r}
for (xx in 1:(length(summary_nature)-2) ) {
  for (yy in (xx+1):(length(summary_nature)-1) ) {
    print(xx)
    print(yy)
    p <- ggplot(summary_nature, aes(x=summary_nature[,xx], y=summary_nature[,yy], color=FIRE_SIZE)) + 
       geom_point() +
      scale_color_manual(labs( x = colnames(summary_nature)[xx], y = colnames(summary_nature)[yy]) )
    print(p)
  }}
  
```

#KNN

```{r}
scaledWildfires <- as.data.frame(scale(summary_nature[1:7], center = TRUE, scale = TRUE))
set.seed(321)


# Splitting data into train and test data
split <- sample.split(summary_nature, SplitRatio = 0.7)
train_wildfires <- subset(summary_nature, split == "TRUE")
test_wildfires <- subset(summary_nature, split == "FALSE")



# Feature Scaling
train_scale <- scale(train_wildfires[, 1:4])
test_scale <- scale(test_wildfires[, 1:4])
  
# Fitting KNN Model to training dataset
classifier_knn <- knn(train = train_scale,
                      test = test_scale,
                      cl = train_wildfires$FIRE_SIZE,
                      k = 1)
classifier_knn

# Confusiin Matrix
cm <- table(test_wildfires$FIRE_SIZE, classifier_knn)
cm
  

# Model Evaluation - Choosing K. Calculate out of Sample error
misClassError <- mean(classifier_knn != test_wildfires$FIRE_SIZE)
print(paste('Accuracy =', 1-misClassError))
  
# K = 3
classifier_knn <- knn(train = train_scale,
                      test = test_scale,
                      cl = train_wildfires$FIRE_SIZE,
                      k = 100)
misClassError <- mean(classifier_knn != test_wildfires$FIRE_SIZE)
print(paste('Accuracy =', 1-misClassError))

```














